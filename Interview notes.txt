Interview notes
=================
Java
=====
Hashmap
---------
Key value
If you insert duplicate key, it will replace the element of the corresponding key.  
HashMap is similar to HashTable, but it is unsynchronized.
Constructors in hashmap:
HashMap() - It is the default constructor which creates an instance of HashMap with an initial capacity of 16 and load factor of 0.75.
HashMap(int initialCapacity)
HashMap(int initialCapacity, float loadFactor)
HashMap(Map map)
Methods:
put
remove
Traversal in hashmap:
for (Map.Entry<String, Integer> e : map.entrySet())
            System.out.println("Key: " + e.getKey()
             + " Value: " + e.getValue());
Node<K,V>
    int hash
    K key
    V value
    Node<K,V> next

Each bucket used for storing data in hashmap in the heap memory is a linked list.
Linked list stores the data in the form of nodes. Each node consists of data and pointer to the next node.
When we add value to hashmap,

map.put("FB","A")
-----------------
Step 1: Find hashcode of the key. (In this case hashcode = 2236)
Step 2: Find Bucket index.
        hashcode & (length-1)
        = 2236 & (16-1)
Bucket index  = 12
Hash-collision - When the bucket already has one or more nodes. 
When hash collision occurs, JVM will check if the same key is already present ("Ea".equals("FB)). If present, then the node will be replaced by the new one. This is why Hashmap cannot have duplicate keys. If that key is not present, this key-value will be added as a new node to the linked list.
Refer to image: C:\Users\QBurst\Documents\StudyMaterial\study_notes\Images\HashMap_working.jpg

map.get("Ea")
-------------
Time complexity is very less.
While calling the get method, JVM will calculate the hashcode of the key and then the bucket from there. Then it will traverse through each node in the bucket and check when the key gets equal to that in the node.

From JAVA 8 onwards, if the number of nodes in a bucket exceeds a threshold (TREEIFY_THRESHOLD), the linked list will be converted to a tree. (Self-balancing Binary Search Tree)
compareTo() method is used to check the order of items.

Streams
----------
Introduced in Java 8, the Stream API is used to process collections of objects. A stream is a sequence of objects that supports various methods which can be pipelined to produce the desired result.
The features of Java stream are –   

A stream is not a data structure instead it takes input from the Collections, Arrays or I/O channels.
Streams don’t change the original data structure, they only provide the result as per the pipelined methods.
Each intermediate operation is lazily executed and returns a stream as a result, hence various intermediate operations can be pipelined. Terminal operations mark the end of the stream and return the result.

Different Operations On Streams-
Intermediate Operations:

map: The map method is used to returns a stream consisting of the results of applying the given function to the elements of this stream.
List number = Arrays.asList(2,3,4,5);
List square = number.stream().map(x->x*x).collect(Collectors.toList());
filter: The filter method is used to select elements as per the Predicate passed as argument.
List names = Arrays.asList("Reflection","Collection","Stream");
List result = names.stream().filter(s->s.startsWith("S")).collect(Collectors.toList());
sorted: The sorted method is used to sort the stream.
List names = Arrays.asList("Reflection","Collection","Stream");
List result = names.stream().sorted().collect(Collectors.toList());
Terminal Operations:

collect: The collect method is used to return the result of the intermediate operations performed on the stream.
List number = Arrays.asList(2,3,4,5,3);
Set square = number.stream().map(x->x*x).collect(Collectors.toSet());
forEach: The forEach method is used to iterate through every element of the stream.
List number = Arrays.asList(2,3,4,5);
number.stream().map(x->x*x).forEach(y->System.out.println(y));
reduce: The reduce method is used to reduce the elements of a stream to a single value.
The reduce method takes a BinaryOperator as a parameter.
List number = Arrays.asList(2,3,4,5);
int even = number.stream().filter(x->x%2==0).reduce(0,(ans,i)-> ans+i);

Here ans variable is assigned 0 as the initial value and i is added to it .

Streams are lazy meaning the intermediate operatio ns are executed only when the terminal operation is invoked. So if we convert a collection to stream and then do map and filter, a new stream will be created. But the filter and map action will not be run yet. At a later point, when this stream.collect is called will the filter and map functions be executed.


Sequential and parallel Streams
--------------------------------
Intel i7 - 4 cores, 8 threads(logical processors)
The number of threads in the common pool is equal to the number of processor cores.

Sequential streams use a single thread to process the pipeline.
List<Integer> listOfNumbers = Arrays.asList(1, 2, 3, 4);
listOfNumbers.stream().forEach(number ->
    System.out.println(number + " " + Thread.currentThread().getName())
); 

The output of this sequential stream is predictable. 
1 main
2 main
3 main
4 main

Parallel streams enable us to execute code in parallel on separate cores. The final result is the combination of each individual outcome.
However, the order of execution is out of our control. It may change every time we run the program:

List<Integer> listOfNumbers = Arrays.asList(1, 2, 3, 4);
listOfNumbers.parallelStream().forEach(number ->
    System.out.println(number + " " + Thread.currentThread().getName())
);

4 ForkJoinPool.commonPool-worker-3
2 ForkJoinPool.commonPool-worker-5
1 ForkJoinPool.commonPool-worker-7
3 main

List<Integer> listOfNumbers = Arrays.asList(1, 2, 3, 4);
int sum = listOfNumbers.parallelStream().reduce(5, Integer::sum);
assertThat(sum).isNotEqualTo(15);
n a sequential stream, the result of this operation would be 15.
But since the reduce operation is handled in parallel, the number five actually gets added up in every worker thread. Therefore, we need to be careful about which operations can be run in parallel.

A sequential stream can be converted to a parallel one when we have actual performance requirements. Given those requirements, we should first run a performance measurement and consider parallelism as a possible optimization strategy.
A large amount of data and many computations done per element indicate that parallelism could be a good option.
On the other hand, a small amount of data, unevenly splitting sources, expensive merge operations and poor memory locality indicate a potential problem for parallel execution.
Arrays are a great data source for parallel execution because they bring the best possible locality and can split cheaply and evenly.

try-catch-finally
-----------------
Scanner scanner = null;
try {
    scanner = new Scanner(new File("test.txt"));
    while (scanner.hasNext()) {
        System.out.println(scanner.nextLine());
    }
} catch (FileNotFoundException e) {
    e.printStackTrace();
} finally {
    if (scanner != null) {
        scanner.close();
    }
}

Finally block will be executed if the exception is present or not.

try-with-resources: Support for try-with-resources — introduced in Java 7 — allows us to declare resources to be used in a try block with the assurance that the resources will be closed after the execution of that block.
The resources declared need to implement the AutoCloseable interface.

try (Scanner scanner = new Scanner(new File("test.txt"))) {
    while (scanner.hasNext()) {
        System.out.println(scanner.nextLine());
    }
} catch (FileNotFoundException fnfe) {
    fnfe.printStackTrace();
}

SOLID principles
-----------------
Single responsibility principle:
Each class for each responsibility.

Open-closed principle:
Classes should be opne foe for extension but closed for modification.
The interfaces are closed for modifications, and you can provide new implementations to extend the functionality of your software.

Liskov substitution:
If class A is a subtype of class B, we should be able to replace B with A without disrupting the behavior of our program.
Eg: 
Interface Car and implementations Motor car and Electric car.

Interface segregation:


Spring security

OAuth
------
Authorization between services.
Terminology:
Resource/Protected resource - Photos in Google Drive.
Resource owner - Entity capable of granting access to the protected resource. In this case, the user holding the google account which has the photos.
Resource server -  Server holding the protected resource. Here, Google Drive resource.
Client - Client is the application that needs the protected resouce. In this case, the photo printing service.
The resource server typically has coupled with it an authorization server.
Authorization server - The server issuing access tokens to the client.
Authorization server gives the client a short lived authorization token. The client gives this back to the authorization server. Then the authorization server also sends the client an access token.
API call to resource server is made by the client with access token.
OAuth flow 1 
OAuth flow 2 - No authorization token. Just access token.
OAuth flow 3 - Communication between microservices. Trusted application. No authentication by the client and no authorization token.
OAUth can also be used for authentication

final keyword
---------------

Lambda
-------
Sometimes we would need somethings and the behaviour could be varying. In such times, we can use interfaces. But then we are not really passing the behaviour(method) but something(class) that does the behaviour.

public interface Greeting{
    public void perform();
}

public class HelloWorldGreeting implements Greeting{
    public void perform(){
        System.out.println("Hello World");
    }
}

public class Greeter {

    public void printGreeting(Greeting greeting){
        greeting.perform();
    }

    public static void main(String[] args){
        Greeter greeter = new Greeter();
        Greeting helloWorldGreeting =  new HelloWorldGreeting();
        greeter.printGreeting(helloWorldGreeting);

        Greeting greeting = () -> System.out.println("Hello World from lambda");
        greeting.perform();
    }
}

Data and objects act as values in java.
eg: 
    Student student = new Student();
    OldStudent oldstudent = student;

or

    String name = "Anna";

From Java 8 onwards, we can assign a block of code to variables.

aBlockOfCode = public void perform(){
                    System.out.println("Hello world");
               }

               removing unnecessary info to:

aBlockOfCode = (){
                    System.out.println("Hello world");
               }

               The actual syntax being:

aBlockOfCode = () -> {
                    System.out.println("Hello world");
               }
    If the body of lambda is just one line then,

aBlockOfCode = () -> System.out.println("Hello world"); 

The above are lambda expressions.

Why lambda
Function as value
Type inference

Lambda function type is interface.
Implementing Thread using Runnable and lambda.

Functional interface
--------------------
An interface with 1 abstract method.
@FunctionalInterface - enforces that the interface is a functional interface. Helps developers notice it. Interfaces to remain functional is important in the case of lambdas.
               

Notes:
======
Heap memory - All objects are maintained.
Stack memory - Object references are maintained.
String is a final class. So it cannot be extended.


